# ExperimentsWithDocker
## TODO list
- https://www.big-data-europe.eu/scalable-sparkhdfs-workbench-using-docker/
- https://github.com/big-data-europe/ansible
- Add HUE
- Add Oozie
- Save data in HDFS using parquet
- Saving daa for Hive (deep down it uses parquet)
- Create a stream application with spark
- Create a job application with spark
- For a more complete experience I will consider to use Apache Ambari
- Use Structured Streaming (see https://www.youtube.com/watch?v=_1byVWTEK1s)
- Looking for a job scheduler - Azkaban seems interesting - Pinterest pinball as well as drake
